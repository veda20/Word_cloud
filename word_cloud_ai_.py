# -*- coding: utf-8 -*-
"""word cloud AI .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DzXABb_Yj_LM4u5f4PEwDgtapU7AVUmY
"""

from google.colab import files
uploaded = files.upload()

text_file = open("disney.txt")
text = text_file.read()
print(type(text))
print("\n")
print(text)
print("\n")
print(len(text))

import nltk
nltk.download('all')
from nltk import sent_tokenize
from nltk import word_tokenize
sentences = sent_tokenize(text)
print(len(sentences))
sentences

words = word_tokenize(text)
print(len(words))
print(words)

from nltk.probability import FreqDist
fdist = FreqDist(words)
fdist.most_common(10)

import matplotlib.pyplot as plt
fdist.plot(10)

words_no_punc =[]
for w in words:
  if w.isalpha():
    words_no_punc.append(w.lower())
print(words_no_punc)
print("\n")
print(len(words_no_punc))

fdist = FreqDist(words_no_punc)
fdist.most_common(10)

fdist.plot(10)

from nltk.corpus import stopwords

#list of stopwords
stopwords = stopwords.words("english")
print(stopwords)

clean_words = []

for w in words_no_punc:
  if w not in stopwords:
    clean_words.append(w)

print(clean_words)
print("\n")
print(len(clean_words))

fdist = FreqDist(clean_words)

fdist.most_common(10)

fdist.plot(10)

from wordcloud import WordCloud
import matplotlib.pyplot as plt
wordcloud = WordCloud().generate(text)
plt.figure(figsize = (12,12))
plt.imshow(wordcloud,interpolation= "bilinear")
plt.axis("off")
plt.show()